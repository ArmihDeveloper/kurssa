Kompletny Kurs: Budowa Autonomicznego Agenta AI do Web Scrapingu
Wstęp
Siemanko! Witaj teraz zera zbudujemy zaawansowanego agenta AI. Nie będzie to byle jaka zabawka – stworzymy bota, który potrafi samodzielnie operować w prawdziwej przeglądarce internetowej, klikać w elementy, wypełniać formularze, a nawet radzić sobie z zabezpieczeniami typu CAPTCHA.

Celem tego kursu jest pokazanie Ci, jak w praktyce wygląda budowa nowoczesnych, autonomicznych systemów. Będziemy używać potężnych narzędzi, takich jak framework Smol Agents, sandboxy w chmurze E2B, sterownik przeglądarki Playwright i modele językowe od OpenAI.

Brzmi skomplikowanie? Bez obaw. Przejdziemy przez wszystko razem, krok po kroku, tłumacząc każdy detal w prosty sposób. Pod koniec tego kursu będziesz mieć działającego, inteligentnego agenta i solidne podstawy do tworzenia własnych, jeszcze bardziej zaawansowanych projektów. Gotowy? Zaczynamy!

Rozdział 1: Teoria w Pigułce – Mózg, Ciało i Zespół
Zanim zaczniemy pisać kod, musimy zrozumieć trzy proste koncepcje.

Mózg i Ciało (Agent AI): Wyobraź sobie superinteligentną osobę (to jest Mózg, czyli duży model językowy jak GPT-4), która potrafi myśleć i planować. Sama w sobie jest jednak bezużyteczna, bo jest zamknięta w pokoju. Teraz daj jej zestaw narzędzi (to jest Ciało): telefon, laptopa, kartę kredytową. Nagle ta sama osoba może rezerwować loty, robić zakupy i sprawdzać pogodę. Agent AI to właśnie takie połączenie – mózgu (LLM), który decyduje, co zrobić, i ciała (narzędzi w kodzie), które te decyzje wykonuje.

Workflow vs. Agent:

Workflow (Przepływ Pracy): To jak składanie mebli z Ikei według instrukcji. Masz listę sztywnych kroków i musisz je wykonać w tej samej kolejności. Jest to proces w pełni zdefiniowany przez programistę.
Agent: To jak zatrudnienie fachowca, któremu dajesz cel: "złóż to biurko". On sam decyduje, czy użyć śrubokręta czy wkrętarki i w jakiej kolejności połączyć elementy, by osiągnąć cel. Jest elastyczny i sam tworzy ścieżkę do rozwiązania problemu. My budujemy właśnie takiego fachowca.
Systemy Wieloagentowe: To już wyższy poziom. Zamiast jednego fachowca od wszystkiego, zatrudniasz całą ekipę budowlaną: architekta (agent-planista), murarza (agent-programista), elektryka (agent-tester). Każdy jest specjalistą w swojej dziedzinie i razem mogą zbudować coś znacznie większego. W tym kursie skupimy się na jednym, ale bardzo uzdolnionym agencie.

Tyle teorii. Czas przygotować nasze stanowisko pracy.

Rozdział 2: Przygotowanie Pola Bitwy
To jest absolutnie najważniejszy rozdział. Dokładne wykonanie tych kroków jest kluczowe dla sukcesu całego projektu.

Krok 2.1: Struktura Projektu
Zanim napiszesz jedną linijkę kodu, zorganizuj sobie pracę. Stworzymy prostą strukturę folderów. Na swoim komputerze (np. na Pulpicie) będziesz mieć jeden główny folder, który będzie wyglądał tak:

moj-agent-scraper/
├── venv/                <-- Folder na wirtualne środowisko (stworzy się automatycznie)
└── scraper_agent.py     <-- Tutaj będzie nasz kod Pythona
Krok 2.2: Terminal – Twój Nowy Najlepszy Kumpel
Wszystkie komendy będziemy wpisywać w terminalu (linii poleceń).

Na Windowsie: Uruchom aplikację PowerShell lub Terminal.
Na macOS: Uruchom aplikację Terminal.
Na Linuxie: Użyj swojej ulubionej konsoli.
Krok 2.3: Tworzenie i Aktywacja Wirtualnego Środowiska (venv)
Dlaczego to robimy? Żeby nie zainstalować naszych narzędzi globalnie i nie narobić bałaganu w systemie. Tworzymy dedykowaną "piaskownicę" tylko dla naszego projektu.

Otwórz terminal.

Stwórz folder projektu i wejdź do niego. Wpisz poniższe komendy jedna po drugiej, naciskając Enter po każdej:

Bash

mkdir moj-agent-scraper
cd moj-agent-scraper
Teraz wszystkie kolejne komendy wykonujesz, będąc wewnątrz folderu moj-agent-scraper.

Stwórz wirtualne środowisko. Ta komenda stworzy folder venv w Twoim projekcie.

Bash

python -m venv venv
(Jeśli na macOS/Linux masz wiele wersji Pythona, być może będziesz musiał użyć python3 zamiast python)

Aktywuj środowisko. To najważniejszy krok! Musisz to robić za każdym razem, gdy otwierasz nowy terminal, by pracować nad tym projektem.

Na Windows (w PowerShell):
PowerShell

.\venv\Scripts\Activate.ps1
Na macOS / Linux:
Bash

source venv/bin/activate
Jak poznać, że się udało? Na początku Twojej linii w terminalu pojawi się napis (venv). Wygląda to mniej więcej tak: (venv) C:\Users\TwojaNazwa\Desktop\moj-agent-scraper>. Jeśli to widzisz, jesteś gotowy do dalszej pracy!

Krok 2.4: Instalacja Niezbędnych Narzędzi (pip)
Gdy środowisko jest aktywne, możemy bezpiecznie instalować nasze biblioteki.

W tym samym terminalu z aktywnym (venv) wpisz:
Bash

pip install smol-agents openai e2b playwright 2captcha-python beautifulsoup4
Po zakończeniu instalacji, Playwright potrzebuje doinstalowania przeglądarek, którymi będzie sterować. Wpisz:
Bash

playwright install
Poczekaj, aż wszystko się pobierze.
Krok 2.5: Klucze API – Twoje Przepustki do Świata AI
Nasz agent będzie korzystał z zewnętrznych usług, które wymagają uwierzytelnienia. Klucz API to po prostu hasło dla programu.

Gdzie zdobyć klucze?

OPENAI_API_KEY: Zaloguj się na platform.openai.com, przejdź do sekcji "API Keys" i stwórz nowy klucz.
E2B_API_KEY: Zarejestruj się na e2b.dev i skopiuj klucz z panelu głównego.
TWOCAPTCHA_API_KEY: Zarejestruj się na 2captcha.com, dodaj środki do konta (wystarczy 1-2$) i skopiuj klucz API z panelu.
Jak i Gdzie Ustawić Klucze?
Musisz ustawić je jako zmienne środowiskowe. Dzięki temu nie będziesz musiał wpisywać ich na stałe w kodzie, co jest niebezpieczne. Ustawiasz je w tym samym terminalu, w którym masz aktywne środowisko (venv). Ta operacja jest tymczasowa – po zamknięciu terminala klucze znikną i trzeba je będzie ustawić ponownie.

Na Windows (w PowerShell):
PowerShell

$env:OPENAI_API_KEY = "sk-..."
$env:E2B_API_KEY = "e2b_..."
$env:TWOCAPTCHA_API_KEY = "twoj_klucz_2captcha"
Na macOS / Linux:
Bash

export OPENAI_API_KEY="sk-..."
export E2B_API_KEY="e2b_..."
export TWOCAPTCHA_API_KEY="twoj_klucz_2captcha"
Zastąp ... swoimi prawdziwymi kluczami. Po wpisaniu tych komend nie pojawi się żaden komunikat – to normalne.

Krok 2.6: Konfiguracja Proxy (Opcjonalnie)
Jeśli chcesz, aby Twój agent korzystał z serwera proxy, przygotuj sobie jego dane (host, port, login, hasło). W naszym kodzie będzie miejsce, gdzie można je wstawić.

Pole bitwy jest gotowe. Czas na budowę broni.

Rozdział 3: Budowa Agenta – Pisanie Kodu
W folderze moj-agent-scraper stwórz plik o nazwie scraper_agent.py. Otwórz go w swoim ulubionym edytorze kodu (np. VS Code, PyCharm, a nawet Notatnik) i wklej poniższy kod. Zaraz omówimy go kawałek po kawałku.
Kod mozesz zobaczyc na stronie Twojego kursu.

Python

# Krok 3.1: Importy i Konfiguracja
import os
import asyncio
from e2b import Sandbox
from playwright.async_api import async_playwright, Page
from twocaptcha import TwoCaptcha
from smol_agents import Agent
from bs4 import BeautifulSoup

# Wczytujemy klucze API ze zmiennych środowiskowych
# Jeśli ich nie ustawiłeś, tutaj program zwróci błąd - i dobrze!
E2B_API_KEY = os.getenv("E2B_API_KEY")
TWOCAPTCHA_API_KEY = os.getenv("TWOCAPTCHA_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Opcjonalna konfiguracja proxy - uzupełnij, jeśli chcesz używać
PROXY_CONFIG = {
    "server": "http://twoj_host_proxy:port", # np. http://123.45.67.89:8080
    "username": "twoj_uzytkownik",
    "password": "twoje_haslo_proxy"
}

# Krok 3.2: Sercem Operacji – Klasa SandboxedBrowser
class SandboxedBrowser:
    """
    Klasa zarządzająca jedną, stałą sesją przeglądarki w sandboksie E2B.
    Utrzymuje stan i pozwala na wykonywanie wielu operacji po kolei.
    """
    def __init__(self, use_proxy: bool = False):
        self.sandbox: Sandbox | None = None
        self.page: Page | None = None
        self.use_proxy = use_proxy
        self.captcha_solver = TwoCaptcha(TWOCAPTCHA_API_KEY)

    async def start(self):
        """Uruchamia sandbox, instaluje zależności i odpala przeglądarkę."""
        print("--- Inicjalizacja: Uruchamiam sandbox E2B... ---")
        self.sandbox = await Sandbox.create(template="base", api_key=E2B_API_KEY)
        
        print("--- Inicjalizacja: Instaluję zależności w sandboksie... ---")
        await self.sandbox.process.start_and_wait(
            "apt-get update && apt-get install -y libnss3 libnspr4 libdbus-1-3 libatk1.0-0 libatk-bridge2.0-0 libcups2 libatspi2.0-0 libxcomposite1 libxdamage1 libxfixes3 libxrandr2 libgbm1 libxkbcommon0 libpango-1.0-0 libcairo2 libasound2"
        )
        await self.sandbox.process.start_and_wait("pip install playwright beautifulsoup4 && playwright install chrome")
        
        print("--- Inicjalizacja: Uruchamiam przeglądarkę Chrome w sandboksie... ---")
        browser_args = ['--headless=new']
        if self.use_proxy:
            browser_args.append(f"--proxy-server={PROXY_CONFIG['server']}")
        
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=True, args=browser_args)
        
        context = await self.browser.new_context()
        if self.use_proxy:
            await context.set_http_credentials({
                'username': PROXY_CONFIG['username'],
                'password': PROXY_CONFIG['password']
            })

        self.page = await context.new_page()
        print("--- Inicjalizacja: Przeglądarka jest gotowa do pracy! ---")

    async def close(self):
        """Zamyka przeglądarkę i sandbox."""
        print("--- Zamykanie: Sprzątam po sobie... ---")
        if hasattr(self, 'browser') and self.browser: await self.browser.close()
        if hasattr(self, 'playwright') and self.playwright: await self.playwright.stop()
        if self.sandbox: await self.sandbox.close()
        print("--- Zamykanie: Sesja zakończona. ---")

    # === NARZĘDZIA DLA AGENTA ===

    async def navigate(self, url: str) -> str:
        """Nawiguje do podanego adresu URL."""
        print(f"--- Narzędzie: Nawiguję do {url} ---")
        await self.page.goto(url, wait_until='domcontentloaded')
        return f"Pomyślnie przeniesiono na stronę: {url}"

    async def click_element(self, selector: str) -> str:
        """Klika na element na stronie używając selektora CSS."""
        print(f"--- Narzędzie: Klikam w element '{selector}' ---")
        await self.page.click(selector, timeout=5000)
        return f"Pomyślnie kliknięto w element '{selector}'."

    async def fill_input(self, selector: str, text: str) -> str:
        """Wypełnia pole tekstowe na stronie."""
        print(f"--- Narzędzie: Wypełniam pole '{selector}' tekstem '{text}' ---")
        await self.page.fill(selector, text)
        return f"Pomyślnie wypełniono pole '{selector}'."

    async def get_content(self) -> str:
        """Pobiera i zwraca całą treść tekstową aktualnej strony."""
        print("--- Narzędzie: Pobieram treść strony... ---")
        content_html = await self.page.content()
        await self.sandbox.filesystem.write("/tmp/page.html", content_html)
        script = """
from bs4 import BeautifulSoup
with open('/tmp/page.html', 'r', encoding='utf-8') as f:
    soup = BeautifulSoup(f, 'html.parser')
    for item in soup(["script", "style"]): item.extract()
    print(soup.get_text(separator=' ', strip=True))
"""
        proc = await self.sandbox.process.start_and_wait(f"python -c \"{script}\"")
        return f"Oto treść strony: {proc.stdout}"


    async def solve_and_fill_captcha(self, captcha_selector: str, input_selector: str) -> str:
        """Znajduje obrazek CAPTCHA, rozwiązuje go i wpisuje wynik do pola."""
        print(f"--- Narzędzie: Rozpoczynam rozwiązywanie CAPTCHA... ---")
        captcha_element = self.page.locator(captcha_selector)
        screenshot_bytes = await captcha_element.screenshot()
        captcha_path_in_sandbox = "/tmp/captcha.png"
        await self.sandbox.filesystem.write(captcha_path_in_sandbox, screenshot_bytes)
        print("--- Krok 1: Zrobiono zrzut ekranu CAPTCHA. Wysyłam do API... ---")
        result = self.captcha_solver.normal(screenshot_bytes)
        captcha_text = result.get('code')
        print(f"--- Krok 2: Otrzymano rozwiązanie: '{captcha_text}' ---")
        await self.fill_input(input_selector, captcha_text)
        return f"Pomyślnie rozwiązano CAPTCHA i wpisano tekst."

# Krok 3.3: Mózg Operacji – Definicja Agenta
def create_agent(browser_session: SandboxedBrowser) -> Agent:
    return Agent(
        name="AgentScraperPro",
        description="Agent-ekspert od web scrapingu, który operuje na stałej sesji przeglądarki. Potrafi nawigować, klikać, wypełniać pola i rozwiązywać CAPTCHA.",
        model="gpt-4-turbo",
        tools=[
            browser_session.navigate,
            browser_session.click_element,
            browser_session.fill_input,
            browser_session.get_content,
            browser_session.solve_and_fill_captcha,
        ],
        api_key=OPENAI_API_KEY
    )

# Krok 3.4: Główna Funkcja 'main' – Dyrygent Orkiestry
async def main():
    browser_session = SandboxedBrowser(use_proxy=False)
    try:
        await browser_session.start()
        agent = create_agent(browser_session)
        
        zadanie = "Wejdź na stronę 'https://quotes.toscrape.com/'. Następnie kliknij w link 'Login' w prawym górnym rogu. Na koniec pobierz całą widoczną treść strony logowania."
        print(f"\n--- Zlecenie dla Agenta: {zadanie} ---\n")

        wynik = await agent.arun(zadanie)
        print(f"\n--- Ostateczny Raport Agenta ---\n{wynik}")

    except Exception as e:
        print(f"Wystąpił nieoczekiwany błąd główny: {e}")
    finally:
        await browser_session.close()

if __name__ == "__main__":
    if not all([OPENAI_API_KEY, E2B_API_KEY, TWOCAPTCHA_API_KEY]):
        print("BŁĄD: Brak jednego lub więcej kluczy API. Ustaw je jako zmienne środowiskowe!")
    else:
        asyncio.run(main())

Omówienie Kodu
Krok 3.1: Importujemy biblioteki i wczytujemy klucze API. Jeśli nie ustawiłeś kluczy, program poinformuje o tym przy próbie uruchomienia.
Krok 3.2: To nasza klasa SandboxedBrowser. __init__ przygotowuje zmienne. start() odpala całą maszynerię (sandbox, instalacje, przeglądarkę). close() po wszystkim sprząta. Metody takie jak Maps czy click_element to narzędzia, które agent będzie wywoływał. Każde z nich operuje na tej samej, jednej instancji przeglądarki (self.page).
Krok 3.3: Funkcja create_agent tworzy instancję agenta. Zwróć uwagę, że w liście tools przekazujemy mu metody obiektu browser_session, a nie luźne funkcje. To jest klucz do utrzymania stanu!
Krok 3.4: Funkcja main jest naszym dyrygentem. Tworzy sesję przeglądarki, tworzy agenta, zleca mu zadanie, a na końcu, w bloku finally, dba o to, by sesja przeglądarki została bezpiecznie zamknięta, nawet jeśli po drodze wystąpi błąd.
Rozdział 4: Uruchomienie i Obserwacja
Wszystko gotowe. Czas na start!

Krok 4.1: Ostateczne Sprawdzenie
Upewnij się, że:

Jesteś w terminalu w folderze moj-agent-scraper.
Twoje wirtualne środowisko (venv) jest aktywne.
Ustawione są klucze API dla tej sesji terminala.
Krok 4.2: Start!
Wpisz w terminalu poniższą komendę i naciśnij Enter:

Bash

python scraper_agent.py
Krok 4.3: Co Się Dzieje na Ekranie?
Nie przeraź się ilością tekstu! To dobrze, że program jest "gadatliwy". Zobaczysz kolejno:

Komunikat "Inicjalizacja: Uruchamiam sandbox E2B...". To może potrwać od kilkunastu sekund do minuty, bo w chmurze tworzy się dla Ciebie wirtualny komputer.
Logi z instalacji zależności w sandboksie.
Komunikat "Przeglądarka jest gotowa do pracy!".
Twoje zlecenie dla agenta.
Komunikaty z poszczególnych narzędzi, które agent zdecyduje się wywołać, np. "--- Narzędzie: Nawiguję do https://quotes.toscrape.com/ ---", a potem "--- Narzędzie: Klikam w element 'a[href="/login"]' ---".
Na sam koniec zobaczysz "Ostateczny Raport Agenta" z odpowiedzią na Twoje zadanie.
Na końcu zobaczysz komunikaty o zamykaniu sesji i sprzątaniu.
Rozdział 5: Co Dalej?
Gratulacje! Właśnie zbudowałeś i uruchomiłeś w pełni funkcjonalnego, autonomicznego agenta AI. To ogromny krok. Co możesz zrobić dalej?

Zlecaj mu inne zadania: Zmień treść zmiennej zadanie w kodzie i eksperymentuj. Spróbuj kazać mu coś wypełnić, np. formularz logowania (ale użyj fałszywych danych!).
Dodaj nowe narzędzia: Może narzędzie do zapisywania pobranej treści do pliku .txt lub .csv w sandboksie, a potem pobierania tego pliku na Twój komputer?
Obsłuż błędy: Nasz kod jest prosty. W realnym świecie dodałbyś więcej bloków try...except w narzędziach, aby agent wiedział, gdy np. nie uda mu się znaleźć jakiegoś elementu na stronie.
Zintegruj monitorowanie: Teraz, gdy widzisz, jak złożony jest proces, pomyśl o zintegrowaniu narzędzia takiego jak Langfuse. Pozwoliłoby Ci to śledzić każdą "myśl" i decyzję agenta w wygodnym panelu graficznym, co jest nieocenione przy dalszym rozwoju.